{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Rupesh Kumar - Iris_Assignment_new.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rupesh05/ML_Workshop---IIT-Kanpur/blob/main/Iris_Assignment_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaYO8Jh2VPJZ"
      },
      "source": [
        "### Import Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPL4aHTJVPJe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "00ab143e-fff1-4e19-f9a8-fb272ec7628d"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "import keras\n",
        "np.random.seed(10)\n",
        "\n",
        "iris = load_iris()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsRa3fVxhhdh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7b671aeb-b003-4e91-81ab-a056cead28ba"
      },
      "source": [
        "#print type of iris \n",
        "type(iris)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Rq79DuqVPJt"
      },
      "source": [
        "### Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDT-J_7fVPJ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75ba1f90-99fe-486e-82ba-69c9c4176600"
      },
      "source": [
        "## Print parent classes of this type\n",
        "print(sklearn.utils.Bunch.__bases__)\n",
        "#shape\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<class 'dict'>,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39PEKY6TVPKG"
      },
      "source": [
        "So, you must have found that iris is a dict object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx5xwqsEVPKJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4def7f5c-f773-4f50-9b88-c4718de69bba"
      },
      "source": [
        "## Print the keys present in iris\n",
        "iris.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9H-FaE8VPKQ"
      },
      "source": [
        "## Create X and Y variables. X is the input features, Y is the output labels\n",
        "X = iris['data']\n",
        "Y = iris['target']\n",
        "Y = np.array(Y).reshape(-1,1)\n",
        "#print(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El7PNESyVPKW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "924f479c-09c3-4aa1-cc41-273f3e6045a8"
      },
      "source": [
        "## Track 5 random samples\n",
        "isamples = np.random.randint(len(X), size = (5))\n",
        "print(isamples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  9 125  15  64 113]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhPKoFG8VPKf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b6f22845-fa88-4987-c23d-f815d90734a2"
      },
      "source": [
        "#Shape of Data\n",
        "iris['data'].shape\n",
        "# Print shapes of X and Y\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4)\n",
            "(150, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDZI2luqVPKk"
      },
      "source": [
        "### Preprocess Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMsZRg27VPKl"
      },
      "source": [
        "#### Convert Labels(Y) to one-hot encoding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2Lg7gzIVPKm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "ec1968f2-ee7a-4709-ea1a-e759c7a96fb5"
      },
      "source": [
        "### Convert Y to 1-hot encoding\n",
        "##Your Code Here\n",
        "def oneHot(y,Ny):\n",
        "   \n",
        "    Y = np.zeros(Ny)\n",
        "    Y[y] = 1\n",
        "    return Y\n",
        "\n",
        "Ny=3\n",
        "Y = np.array([oneHot(y,Ny) for y in Y])\n",
        "# Look at converted Y for the random samples we are tracking\n",
        "print(Y[isamples])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fnLz0hfVPKr"
      },
      "source": [
        "### Its time to split your model into training and testing samples "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUjmbjS2VPKs"
      },
      "source": [
        "### split the data into 80% training and 20% testing \n",
        "### Split X into two variables X_train and X_test\n",
        "### Split Y correspondingly into two variables Y_train and Y_test\n",
        "\n",
        "### Your Code Her\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(X)\n",
        "ef = pd.DataFrame(Y)\n",
        "msk = np.random.rand(len(df)) <= 0.8\n",
        "X_train = df[msk]\n",
        "X_test = df[~msk]\n",
        "Y_train = ef[msk]\n",
        "Y_test = ef[~msk].values\n",
        "#print(len(X_train),len(X_test),len(Y_train),len(Y_test))\n",
        "#print(X_train)\n",
        "#print(Y_train)\n",
        "#print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKRUScMIVPKw"
      },
      "source": [
        "### Data Normalization/Scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3o9cGYGVPKx"
      },
      "source": [
        "### Normalize data to be of zero mean and unit variance\n",
        "mean = np.sum(X_train, axis=0)/X_train.shape[0]\n",
        "X1 = X_train - mean\n",
        "stddev = np.sqrt(np.sum(X1*X1, axis=0)/X_train.shape[0])\n",
        "#print(mean)\n",
        "#print(stddev)\n",
        "X_normalised = (X_train - mean)/(stddev+1e-8)\n",
        "#print(X_normalised)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xjpev8BVPK1"
      },
      "source": [
        "Note: If the first 5 samples of X_train and Y_train looks like the one given below\n",
        "then congratulations! You are on the right track;\n",
        "If not, then persistance is the key to success :)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VhqEGPVVPK2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2345
        },
        "outputId": "f9d397f1-96d1-4013-c86c-993bfd069aa5"
      },
      "source": [
        "## Print and observe the normalized inputs and compare with older inputs\n",
        "print(X_normalised,\"normalise data \")\n",
        "print(X_train,\"Initial data \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            0         1         2         3\n",
            "0   -0.961097  1.066880 -1.384347 -1.366022\n",
            "1   -1.208236 -0.110238 -1.384347 -1.366022\n",
            "2   -1.455375  0.360609 -1.441350 -1.366022\n",
            "3   -1.578944  0.125186 -1.327345 -1.366022\n",
            "4   -1.084666  1.302303 -1.384347 -1.366022\n",
            "5   -0.590388  2.008574 -1.213340 -1.100407\n",
            "6   -1.578944  0.831456 -1.384347 -1.233214\n",
            "7   -1.084666  0.831456 -1.327345 -1.366022\n",
            "9   -1.208236  0.125186 -1.327345 -1.498830\n",
            "10  -0.590388  1.537727 -1.327345 -1.366022\n",
            "12  -1.331805 -0.110238 -1.384347 -1.498830\n",
            "13  -1.949653 -0.110238 -1.555355 -1.498830\n",
            "14  -0.096110  2.243998 -1.498352 -1.366022\n",
            "16  -0.590388  2.008574 -1.441350 -1.100407\n",
            "17  -0.961097  1.066880 -1.384347 -1.233214\n",
            "18  -0.219679  1.773150 -1.213340 -1.233214\n",
            "19  -0.961097  1.773150 -1.327345 -1.233214\n",
            "20  -0.590388  0.831456 -1.213340 -1.366022\n",
            "21  -0.961097  1.537727 -1.327345 -1.100407\n",
            "22  -1.578944  1.302303 -1.612357 -1.366022\n",
            "23  -0.961097  0.596033 -1.213340 -0.967599\n",
            "24  -1.331805  0.831456 -1.099335 -1.366022\n",
            "25  -1.084666 -0.110238 -1.270342 -1.366022\n",
            "26  -1.084666  0.831456 -1.270342 -1.100407\n",
            "28  -0.837527  0.831456 -1.384347 -1.366022\n",
            "30  -1.331805  0.125186 -1.270342 -1.366022\n",
            "31  -0.590388  0.831456 -1.327345 -1.100407\n",
            "32  -0.837527  2.479421 -1.327345 -1.498830\n",
            "33  -0.466818  2.714845 -1.384347 -1.366022\n",
            "35  -1.084666  0.360609 -1.498352 -1.366022\n",
            "..        ...       ...       ...       ...\n",
            "116  0.768877 -0.110238  0.952757  0.758901\n",
            "117  2.251712  1.773150  1.636787  1.290132\n",
            "118  2.251712 -1.051932  1.750792  1.422940\n",
            "119  0.151029 -1.993626  0.667744  0.360478\n",
            "120  1.263156  0.360609  1.066762  1.422940\n",
            "121 -0.343249 -0.581085  0.610741  1.024516\n",
            "122  2.251712 -0.581085  1.636787  1.024516\n",
            "123  0.521738 -0.816509  0.610741  0.758901\n",
            "124  1.016016  0.596033  1.066762  1.157324\n",
            "125  1.633864  0.360609  1.237769  0.758901\n",
            "126  0.398169 -0.581085  0.553739  0.758901\n",
            "127  0.274599 -0.110238  0.610741  0.758901\n",
            "128  0.645308 -0.581085  1.009759  1.157324\n",
            "129  1.633864 -0.110238  1.123764  0.493286\n",
            "130  1.881003 -0.581085  1.294772  0.891709\n",
            "133  0.521738 -0.581085  0.724747  0.360478\n",
            "134  0.274599 -1.051932  1.009759  0.227670\n",
            "135  2.251712 -0.110238  1.294772  1.422940\n",
            "137  0.645308  0.125186  0.952757  0.758901\n",
            "138  0.151029 -0.110238  0.553739  0.758901\n",
            "139  1.263156  0.125186  0.895754  1.157324\n",
            "141  1.263156  0.125186  0.724747  1.422940\n",
            "142 -0.096110 -0.816509  0.724747  0.891709\n",
            "143  1.139586  0.360609  1.180767  1.422940\n",
            "144  1.016016  0.596033  1.066762  1.688555\n",
            "145  1.016016 -0.110238  0.781749  1.422940\n",
            "146  0.521738 -1.287356  0.667744  0.891709\n",
            "147  0.768877 -0.110238  0.781749  1.024516\n",
            "148  0.398169  0.831456  0.895754  1.422940\n",
            "149  0.027460 -0.110238  0.724747  0.758901\n",
            "\n",
            "[126 rows x 4 columns] normalise data \n",
            "       0    1    2    3\n",
            "0    5.1  3.5  1.4  0.2\n",
            "1    4.9  3.0  1.4  0.2\n",
            "2    4.7  3.2  1.3  0.2\n",
            "3    4.6  3.1  1.5  0.2\n",
            "4    5.0  3.6  1.4  0.2\n",
            "5    5.4  3.9  1.7  0.4\n",
            "6    4.6  3.4  1.4  0.3\n",
            "7    5.0  3.4  1.5  0.2\n",
            "9    4.9  3.1  1.5  0.1\n",
            "10   5.4  3.7  1.5  0.2\n",
            "12   4.8  3.0  1.4  0.1\n",
            "13   4.3  3.0  1.1  0.1\n",
            "14   5.8  4.0  1.2  0.2\n",
            "16   5.4  3.9  1.3  0.4\n",
            "17   5.1  3.5  1.4  0.3\n",
            "18   5.7  3.8  1.7  0.3\n",
            "19   5.1  3.8  1.5  0.3\n",
            "20   5.4  3.4  1.7  0.2\n",
            "21   5.1  3.7  1.5  0.4\n",
            "22   4.6  3.6  1.0  0.2\n",
            "23   5.1  3.3  1.7  0.5\n",
            "24   4.8  3.4  1.9  0.2\n",
            "25   5.0  3.0  1.6  0.2\n",
            "26   5.0  3.4  1.6  0.4\n",
            "28   5.2  3.4  1.4  0.2\n",
            "30   4.8  3.1  1.6  0.2\n",
            "31   5.4  3.4  1.5  0.4\n",
            "32   5.2  4.1  1.5  0.1\n",
            "33   5.5  4.2  1.4  0.2\n",
            "35   5.0  3.2  1.2  0.2\n",
            "..   ...  ...  ...  ...\n",
            "116  6.5  3.0  5.5  1.8\n",
            "117  7.7  3.8  6.7  2.2\n",
            "118  7.7  2.6  6.9  2.3\n",
            "119  6.0  2.2  5.0  1.5\n",
            "120  6.9  3.2  5.7  2.3\n",
            "121  5.6  2.8  4.9  2.0\n",
            "122  7.7  2.8  6.7  2.0\n",
            "123  6.3  2.7  4.9  1.8\n",
            "124  6.7  3.3  5.7  2.1\n",
            "125  7.2  3.2  6.0  1.8\n",
            "126  6.2  2.8  4.8  1.8\n",
            "127  6.1  3.0  4.9  1.8\n",
            "128  6.4  2.8  5.6  2.1\n",
            "129  7.2  3.0  5.8  1.6\n",
            "130  7.4  2.8  6.1  1.9\n",
            "133  6.3  2.8  5.1  1.5\n",
            "134  6.1  2.6  5.6  1.4\n",
            "135  7.7  3.0  6.1  2.3\n",
            "137  6.4  3.1  5.5  1.8\n",
            "138  6.0  3.0  4.8  1.8\n",
            "139  6.9  3.1  5.4  2.1\n",
            "141  6.9  3.1  5.1  2.3\n",
            "142  5.8  2.7  5.1  1.9\n",
            "143  6.8  3.2  5.9  2.3\n",
            "144  6.7  3.3  5.7  2.5\n",
            "145  6.7  3.0  5.2  2.3\n",
            "146  6.3  2.5  5.0  1.9\n",
            "147  6.5  3.0  5.2  2.0\n",
            "148  6.2  3.4  5.4  2.3\n",
            "149  5.9  3.0  5.1  1.8\n",
            "\n",
            "[126 rows x 4 columns] Initial data \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhjhim59VPK6"
      },
      "source": [
        "### Training time (using Neural Networks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc1EraozVPK8"
      },
      "source": [
        "- create your NN model with given structure (4 input neurons, 8 hidden neurons and 3 output neurons)\n",
        "- use 'relu' activation in hidden layer \n",
        "- use softmax activation in output\n",
        "- Compile your model using 'categorical_crossentropy' loss function and sgd optimizer\n",
        "- Track the accuracy metric of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWKOMtk2VPK9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "59b7cd6e-695e-466d-8d67-5856a6057159"
      },
      "source": [
        "## Define the model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "Nx = 4\n",
        "x = Input(shape=(Nx,)) \n",
        "\n",
        "y = Dense(8, activation='relu')(x) \n",
        "\n",
        "y = Dense(3, activation='softmax')(y)\n",
        "model = Model(inputs=x, outputs=y)\n",
        "model.compile(optimizer=optimizers.sgd(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJyiYMsYVPLC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "1ca872c9-6ab8-48f5-b9d8-dab23e509368"
      },
      "source": [
        "## Print the model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 40        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 27        \n",
            "=================================================================\n",
            "Total params: 67\n",
            "Trainable params: 67\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdG2o8j_VPLF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1854
        },
        "outputId": "5ea07b2a-ad3f-46db-c0fa-366fca2a48b9"
      },
      "source": [
        "## Fit the model to data\n",
        "model.fit(X_normalised, Y_train, epochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "126/126 [==============================] - 0s 74us/step - loss: 1.0120 - acc: 0.4127\n",
            "Epoch 2/50\n",
            "126/126 [==============================] - 0s 81us/step - loss: 1.0100 - acc: 0.4127\n",
            "Epoch 3/50\n",
            "126/126 [==============================] - 0s 82us/step - loss: 1.0081 - acc: 0.4127\n",
            "Epoch 4/50\n",
            "126/126 [==============================] - 0s 111us/step - loss: 1.0062 - acc: 0.4127\n",
            "Epoch 5/50\n",
            "126/126 [==============================] - 0s 98us/step - loss: 1.0043 - acc: 0.4127\n",
            "Epoch 6/50\n",
            "126/126 [==============================] - 0s 80us/step - loss: 1.0024 - acc: 0.4206\n",
            "Epoch 7/50\n",
            "126/126 [==============================] - 0s 64us/step - loss: 1.0005 - acc: 0.4206\n",
            "Epoch 8/50\n",
            "126/126 [==============================] - 0s 77us/step - loss: 0.9986 - acc: 0.4206\n",
            "Epoch 9/50\n",
            "126/126 [==============================] - 0s 80us/step - loss: 0.9967 - acc: 0.4286\n",
            "Epoch 10/50\n",
            "126/126 [==============================] - 0s 65us/step - loss: 0.9949 - acc: 0.4286\n",
            "Epoch 11/50\n",
            "126/126 [==============================] - 0s 100us/step - loss: 0.9930 - acc: 0.4286\n",
            "Epoch 12/50\n",
            "126/126 [==============================] - 0s 55us/step - loss: 0.9912 - acc: 0.4286\n",
            "Epoch 13/50\n",
            "126/126 [==============================] - 0s 71us/step - loss: 0.9893 - acc: 0.4286\n",
            "Epoch 14/50\n",
            "126/126 [==============================] - 0s 88us/step - loss: 0.9876 - acc: 0.4286\n",
            "Epoch 15/50\n",
            "126/126 [==============================] - 0s 113us/step - loss: 0.9857 - acc: 0.4286\n",
            "Epoch 16/50\n",
            "126/126 [==============================] - 0s 103us/step - loss: 0.9839 - acc: 0.4286\n",
            "Epoch 17/50\n",
            "126/126 [==============================] - 0s 107us/step - loss: 0.9821 - acc: 0.4286\n",
            "Epoch 18/50\n",
            "126/126 [==============================] - 0s 106us/step - loss: 0.9804 - acc: 0.4365\n",
            "Epoch 19/50\n",
            "126/126 [==============================] - 0s 82us/step - loss: 0.9786 - acc: 0.4365\n",
            "Epoch 20/50\n",
            "126/126 [==============================] - 0s 78us/step - loss: 0.9769 - acc: 0.4365\n",
            "Epoch 21/50\n",
            "126/126 [==============================] - 0s 77us/step - loss: 0.9751 - acc: 0.4365\n",
            "Epoch 22/50\n",
            "126/126 [==============================] - 0s 77us/step - loss: 0.9734 - acc: 0.4365\n",
            "Epoch 23/50\n",
            "126/126 [==============================] - 0s 72us/step - loss: 0.9716 - acc: 0.4365\n",
            "Epoch 24/50\n",
            "126/126 [==============================] - 0s 72us/step - loss: 0.9699 - acc: 0.4365\n",
            "Epoch 25/50\n",
            "126/126 [==============================] - 0s 82us/step - loss: 0.9682 - acc: 0.4365\n",
            "Epoch 26/50\n",
            "126/126 [==============================] - 0s 76us/step - loss: 0.9665 - acc: 0.4524\n",
            "Epoch 27/50\n",
            "126/126 [==============================] - 0s 74us/step - loss: 0.9648 - acc: 0.4524\n",
            "Epoch 28/50\n",
            "126/126 [==============================] - 0s 78us/step - loss: 0.9632 - acc: 0.4524\n",
            "Epoch 29/50\n",
            "126/126 [==============================] - 0s 74us/step - loss: 0.9615 - acc: 0.4524\n",
            "Epoch 30/50\n",
            "126/126 [==============================] - 0s 76us/step - loss: 0.9599 - acc: 0.4524\n",
            "Epoch 31/50\n",
            "126/126 [==============================] - 0s 79us/step - loss: 0.9582 - acc: 0.4524\n",
            "Epoch 32/50\n",
            "126/126 [==============================] - 0s 75us/step - loss: 0.9566 - acc: 0.4524\n",
            "Epoch 33/50\n",
            "126/126 [==============================] - 0s 79us/step - loss: 0.9550 - acc: 0.4524\n",
            "Epoch 34/50\n",
            "126/126 [==============================] - 0s 58us/step - loss: 0.9534 - acc: 0.4524\n",
            "Epoch 35/50\n",
            "126/126 [==============================] - 0s 68us/step - loss: 0.9517 - acc: 0.4524\n",
            "Epoch 36/50\n",
            "126/126 [==============================] - 0s 76us/step - loss: 0.9501 - acc: 0.4524\n",
            "Epoch 37/50\n",
            "126/126 [==============================] - 0s 72us/step - loss: 0.9485 - acc: 0.4524\n",
            "Epoch 38/50\n",
            "126/126 [==============================] - 0s 89us/step - loss: 0.9469 - acc: 0.4524\n",
            "Epoch 39/50\n",
            "126/126 [==============================] - 0s 89us/step - loss: 0.9454 - acc: 0.4524\n",
            "Epoch 40/50\n",
            "126/126 [==============================] - 0s 68us/step - loss: 0.9438 - acc: 0.4524\n",
            "Epoch 41/50\n",
            "126/126 [==============================] - 0s 74us/step - loss: 0.9422 - acc: 0.4524\n",
            "Epoch 42/50\n",
            "126/126 [==============================] - 0s 79us/step - loss: 0.9407 - acc: 0.4524\n",
            "Epoch 43/50\n",
            "126/126 [==============================] - 0s 84us/step - loss: 0.9391 - acc: 0.4524\n",
            "Epoch 44/50\n",
            "126/126 [==============================] - 0s 83us/step - loss: 0.9376 - acc: 0.4603\n",
            "Epoch 45/50\n",
            "126/126 [==============================] - 0s 76us/step - loss: 0.9360 - acc: 0.4603\n",
            "Epoch 46/50\n",
            "126/126 [==============================] - 0s 78us/step - loss: 0.9345 - acc: 0.4603\n",
            "Epoch 47/50\n",
            "126/126 [==============================] - 0s 80us/step - loss: 0.9330 - acc: 0.4683\n",
            "Epoch 48/50\n",
            "126/126 [==============================] - 0s 87us/step - loss: 0.9315 - acc: 0.4603\n",
            "Epoch 49/50\n",
            "126/126 [==============================] - 0s 92us/step - loss: 0.9300 - acc: 0.4603\n",
            "Epoch 50/50\n",
            "126/126 [==============================] - 0s 76us/step - loss: 0.9285 - acc: 0.4683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbac0cac470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEiYG3GWVPLJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1835
        },
        "outputId": "f80b4a7b-997d-4912-9918-31109e270d4a"
      },
      "source": [
        "## Test the accuracy of the model on test data\n",
        "history = model.fit(X_normalised, Y_train, epochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "126/126 [==============================] - 0s 72us/step - loss: 1.1282 - acc: 0.3254\n",
            "Epoch 2/50\n",
            "126/126 [==============================] - 0s 63us/step - loss: 1.1255 - acc: 0.3333\n",
            "Epoch 3/50\n",
            "126/126 [==============================] - 0s 50us/step - loss: 1.1227 - acc: 0.3413\n",
            "Epoch 4/50\n",
            "126/126 [==============================] - 0s 70us/step - loss: 1.1200 - acc: 0.3413\n",
            "Epoch 5/50\n",
            "126/126 [==============================] - 0s 63us/step - loss: 1.1173 - acc: 0.3413\n",
            "Epoch 6/50\n",
            "126/126 [==============================] - 0s 74us/step - loss: 1.1146 - acc: 0.3413\n",
            "Epoch 7/50\n",
            "126/126 [==============================] - 0s 69us/step - loss: 1.1119 - acc: 0.3413\n",
            "Epoch 8/50\n",
            "126/126 [==============================] - 0s 59us/step - loss: 1.1093 - acc: 0.3413\n",
            "Epoch 9/50\n",
            "126/126 [==============================] - 0s 50us/step - loss: 1.1066 - acc: 0.3413\n",
            "Epoch 10/50\n",
            "126/126 [==============================] - 0s 56us/step - loss: 1.1041 - acc: 0.3413\n",
            "Epoch 11/50\n",
            "126/126 [==============================] - 0s 62us/step - loss: 1.1015 - acc: 0.3492\n",
            "Epoch 12/50\n",
            "126/126 [==============================] - 0s 61us/step - loss: 1.0989 - acc: 0.3492\n",
            "Epoch 13/50\n",
            "126/126 [==============================] - 0s 73us/step - loss: 1.0963 - acc: 0.3651\n",
            "Epoch 14/50\n",
            "126/126 [==============================] - 0s 66us/step - loss: 1.0938 - acc: 0.3730\n",
            "Epoch 15/50\n",
            "126/126 [==============================] - 0s 76us/step - loss: 1.0913 - acc: 0.3730\n",
            "Epoch 16/50\n",
            "126/126 [==============================] - 0s 69us/step - loss: 1.0888 - acc: 0.3810\n",
            "Epoch 17/50\n",
            "126/126 [==============================] - 0s 64us/step - loss: 1.0864 - acc: 0.3810\n",
            "Epoch 18/50\n",
            "126/126 [==============================] - 0s 71us/step - loss: 1.0839 - acc: 0.3810\n",
            "Epoch 19/50\n",
            "126/126 [==============================] - 0s 68us/step - loss: 1.0815 - acc: 0.3810\n",
            "Epoch 20/50\n",
            "126/126 [==============================] - 0s 70us/step - loss: 1.0791 - acc: 0.3889\n",
            "Epoch 21/50\n",
            "126/126 [==============================] - 0s 68us/step - loss: 1.0767 - acc: 0.3968\n",
            "Epoch 22/50\n",
            "126/126 [==============================] - 0s 66us/step - loss: 1.0743 - acc: 0.3968\n",
            "Epoch 23/50\n",
            "126/126 [==============================] - 0s 68us/step - loss: 1.0719 - acc: 0.3968\n",
            "Epoch 24/50\n",
            "126/126 [==============================] - 0s 63us/step - loss: 1.0696 - acc: 0.3968\n",
            "Epoch 25/50\n",
            "126/126 [==============================] - 0s 67us/step - loss: 1.0672 - acc: 0.3968\n",
            "Epoch 26/50\n",
            "126/126 [==============================] - 0s 70us/step - loss: 1.0650 - acc: 0.3968\n",
            "Epoch 27/50\n",
            "126/126 [==============================] - 0s 72us/step - loss: 1.0627 - acc: 0.3968\n",
            "Epoch 28/50\n",
            "126/126 [==============================] - 0s 70us/step - loss: 1.0604 - acc: 0.3889\n",
            "Epoch 29/50\n",
            "126/126 [==============================] - 0s 64us/step - loss: 1.0581 - acc: 0.3889\n",
            "Epoch 30/50\n",
            "126/126 [==============================] - 0s 66us/step - loss: 1.0559 - acc: 0.3889\n",
            "Epoch 31/50\n",
            "126/126 [==============================] - 0s 66us/step - loss: 1.0536 - acc: 0.3889\n",
            "Epoch 32/50\n",
            "126/126 [==============================] - 0s 66us/step - loss: 1.0514 - acc: 0.3889\n",
            "Epoch 33/50\n",
            "126/126 [==============================] - 0s 71us/step - loss: 1.0492 - acc: 0.3889\n",
            "Epoch 34/50\n",
            "126/126 [==============================] - 0s 64us/step - loss: 1.0471 - acc: 0.3889\n",
            "Epoch 35/50\n",
            "126/126 [==============================] - 0s 60us/step - loss: 1.0449 - acc: 0.3889\n",
            "Epoch 36/50\n",
            "126/126 [==============================] - 0s 61us/step - loss: 1.0427 - acc: 0.3889\n",
            "Epoch 37/50\n",
            "126/126 [==============================] - 0s 67us/step - loss: 1.0406 - acc: 0.3889\n",
            "Epoch 38/50\n",
            "126/126 [==============================] - 0s 57us/step - loss: 1.0385 - acc: 0.3968\n",
            "Epoch 39/50\n",
            "126/126 [==============================] - 0s 88us/step - loss: 1.0363 - acc: 0.3968\n",
            "Epoch 40/50\n",
            "126/126 [==============================] - 0s 97us/step - loss: 1.0342 - acc: 0.3968\n",
            "Epoch 41/50\n",
            "126/126 [==============================] - 0s 120us/step - loss: 1.0321 - acc: 0.3968\n",
            "Epoch 42/50\n",
            "126/126 [==============================] - 0s 94us/step - loss: 1.0301 - acc: 0.3968\n",
            "Epoch 43/50\n",
            "126/126 [==============================] - 0s 90us/step - loss: 1.0280 - acc: 0.3968\n",
            "Epoch 44/50\n",
            "126/126 [==============================] - 0s 84us/step - loss: 1.0259 - acc: 0.3968\n",
            "Epoch 45/50\n",
            "126/126 [==============================] - 0s 121us/step - loss: 1.0239 - acc: 0.3968\n",
            "Epoch 46/50\n",
            "126/126 [==============================] - 0s 79us/step - loss: 1.0219 - acc: 0.4048\n",
            "Epoch 47/50\n",
            "126/126 [==============================] - 0s 74us/step - loss: 1.0199 - acc: 0.4048\n",
            "Epoch 48/50\n",
            "126/126 [==============================] - 0s 74us/step - loss: 1.0179 - acc: 0.4048\n",
            "Epoch 49/50\n",
            "126/126 [==============================] - 0s 83us/step - loss: 1.0159 - acc: 0.4127\n",
            "Epoch 50/50\n",
            "126/126 [==============================] - 0s 59us/step - loss: 1.0139 - acc: 0.4127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yCesywNVPLO"
      },
      "source": [
        "### Confusion Matrix and Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu3uceSkVPLQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "eb05a04e-38c4-42a9-fbe9-ab1a44a460b6"
      },
      "source": [
        "### Lastly, report the accuracy of your model and print the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)  # Evaluate the model\n",
        "print('Accuracy :%0.3f'%accuracy)\n",
        "Y_pred = model.predict(X_test)\n",
        "# Confusion Matrix\n",
        "\n",
        "confusion_matrix(np.argmax(Y_test, axis=1), np.argmax(Y_pred, axis = 1 ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :0.208\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0, 10],\n",
              "       [ 0,  0,  9],\n",
              "       [ 0,  0,  5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}